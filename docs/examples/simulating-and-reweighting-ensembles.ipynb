{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jax and Equinox imports\n",
    "from functools import partial\n",
    "\n",
    "import equinox as eqx\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jaxtyping import PRNGKeyArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting imports and functions\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "\n",
    "def plot_image(image, fig, ax, cmap=\"gray\", label=None, **kwargs):\n",
    "    im = ax.imshow(image, cmap=cmap, origin=\"lower\", **kwargs)\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "    fig.colorbar(im, cax=cax)\n",
    "    if label is not None:\n",
    "        ax.set(title=label)\n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/home/levans/venvs/cryojax/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# CryoJAX imports\n",
    "\n",
    "import cryojax.simulator as cxs\n",
    "from cryojax.data import (\n",
    "    RelionParticleParameterDataset,\n",
    "    RelionParticleParameters,\n",
    "    RelionParticleStackDataset,\n",
    "    write_simulated_image_stack_from_starfile,\n",
    "    write_starfile_with_particle_parameters,\n",
    ")\n",
    "from cryojax.io import read_atoms_from_pdb\n",
    "from cryojax.rotations import SO3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulating Ensembles and doing Ensemble Reweighting\n",
    "\n",
    "In this tutorial we will generate a heterogeneous dataset by defining a distribution on multiple atomic structures. We will then compute a likelihood matrix\n",
    "$$ P_{nm} = p(y_n | x_m) $$\n",
    "\n",
    "where $y_n$ is a data point and $x_m$ is a structure in the ensemble. We will define the likelihood through one of cryoJAX's distributions, although in principle any distribution works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate a starfile\n",
    "\n",
    "First, we will just follow the tutorial `simulate-relion-dataset.ipynb` to generate a starfile. No ensemble stuff yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@partial(eqx.filter_vmap, in_axes=(0, None), out_axes=eqx.if_array(0))\n",
    "def make_particle_parameters(\n",
    "    key: PRNGKeyArray, instrument_config: cxs.InstrumentConfig\n",
    ") -> RelionParticleParameters:\n",
    "    # Generate random parameters\n",
    "\n",
    "    # Pose\n",
    "    # ... instantiate rotations\n",
    "\n",
    "    key, subkey = jax.random.split(key)  # split the key to use for the next random number\n",
    "\n",
    "    rotation = SO3.sample_uniform(subkey)\n",
    "    key, subkey = jax.random.split(key)  # do this everytime you use a key!!\n",
    "\n",
    "    # ... now in-plane translation\n",
    "    ny, nx = instrument_config.shape\n",
    "    offset_in_angstroms = (\n",
    "        jax.random.uniform(subkey, (2,), minval=-0.2, maxval=0.2)\n",
    "        * jnp.asarray((nx, ny))\n",
    "        * instrument_config.pixel_size\n",
    "    )\n",
    "    # ... build the pose\n",
    "    pose = cxs.EulerAnglePose.from_rotation_and_translation(rotation, offset_in_angstroms)\n",
    "\n",
    "    # CTF Parameters\n",
    "    # ... defocus\n",
    "    defocus_in_angstroms = jax.random.uniform(subkey, (), minval=1000, maxval=1500)\n",
    "    key, subkey = jax.random.split(key)\n",
    "\n",
    "    astigmatism_in_angstroms = jax.random.uniform(subkey, (), minval=0, maxval=100)\n",
    "    key, subkey = jax.random.split(key)\n",
    "\n",
    "    astigmatism_angle = jax.random.uniform(subkey, (), minval=0, maxval=jnp.pi)\n",
    "    key, subkey = jax.random.split(key)\n",
    "\n",
    "    phase_shift = jax.random.uniform(subkey, (), minval=0, maxval=0)\n",
    "    # no more random numbers needed\n",
    "\n",
    "    # now generate your non-random values\n",
    "    spherical_aberration_in_mm = 2.7\n",
    "    amplitude_contrast_ratio = 0.1\n",
    "\n",
    "    # ... build the CTF\n",
    "    transfer_theory = cxs.ContrastTransferTheory(\n",
    "        ctf=cxs.AberratedAstigmaticCTF(\n",
    "            defocus_in_angstroms=defocus_in_angstroms,\n",
    "            astigmatism_in_angstroms=astigmatism_in_angstroms,\n",
    "            astigmatism_angle=astigmatism_angle,\n",
    "            spherical_aberration_in_mm=spherical_aberration_in_mm,\n",
    "        ),\n",
    "        amplitude_contrast_ratio=amplitude_contrast_ratio,\n",
    "        phase_shift=phase_shift,\n",
    "    )\n",
    "    relion_particle_parameters = RelionParticleParameters(\n",
    "        instrument_config=instrument_config,\n",
    "        pose=pose,\n",
    "        transfer_theory=transfer_theory,\n",
    "    )\n",
    "    return relion_particle_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate instrument config\n",
    "instrument_config = cxs.InstrumentConfig(\n",
    "    shape=(128, 128),\n",
    "    pixel_size=1.5,\n",
    "    voltage_in_kilovolts=300.0,\n",
    "    pad_scale=1.0,  # no padding\n",
    ")\n",
    "\n",
    "# Generate RNG keys\n",
    "number_of_images = 100\n",
    "keys = jax.random.split(jax.random.key(0), number_of_images)\n",
    "\n",
    "# ... instantiate the RelionParticleDataset\n",
    "particle_parameters = make_particle_parameters(keys, instrument_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... generate the starfile\n",
    "write_starfile_with_particle_parameters(\n",
    "    particle_parameters,\n",
    "    \"./outputs/heterogeneous_relion_dataset.star\",\n",
    "    mrc_batch_size=50,\n",
    "    overwrite=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulating images by choosing a random structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First load the starfile\n",
    "\n",
    "path_to_mrc_files = \"./outputs/relion_dataset_particles/heterogeneous\"\n",
    "\n",
    "parameter_dataset = RelionParticleParameterDataset(\n",
    "    path_to_starfile=\"./outputs/heterogeneous_relion_dataset.star\",  # starfile we created\n",
    "    path_to_relion_project=path_to_mrc_files,  # here is where the mrcs will be saved\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cryojax.constants import get_tabulated_scattering_factor_parameters\n",
    "\n",
    "\n",
    "filenames = [\"./data/groel_chainA.pdb\", \"./data/groel_chainA_holo.pdb\"]\n",
    "\n",
    "box_size = parameter_dataset[0].instrument_config.shape[0]\n",
    "\n",
    "potentials = []\n",
    "voxel_size = parameter_dataset[0].instrument_config.pixel_size\n",
    "for filename in filenames:\n",
    "    # Load the atomic structure and transform into a potential\n",
    "    atom_positions, atom_identities, bfactors = read_atoms_from_pdb(\n",
    "        filename, center=True, select=\"not element H\", loads_b_factors=True\n",
    "    )\n",
    "    scattering_factor_parameters = get_tabulated_scattering_factor_parameters(\n",
    "        atom_identities\n",
    "    )\n",
    "    atomic_potential = cxs.PengAtomicPotential(\n",
    "        atom_positions,\n",
    "        scattering_factor_a=scattering_factor_parameters[\"a\"],\n",
    "        scattering_factor_b=scattering_factor_parameters[\"b\"],\n",
    "        b_factors=bfactors,\n",
    "    )\n",
    "    # Convert to a real voxel grid\n",
    "    # This step is optional, you could use the atomic potential directly!\n",
    "    real_voxel_grid = atomic_potential.as_real_voxel_grid(\n",
    "        shape=(box_size, box_size, box_size), voxel_size=voxel_size\n",
    "    )\n",
    "    potential = cxs.FourierVoxelGridPotential.from_real_voxel_grid(\n",
    "        real_voxel_grid, voxel_size, pad_scale=2\n",
    "    )\n",
    "    potentials.append(potential)\n",
    "\n",
    "potentials = tuple(potentials)\n",
    "potential_integrator = cxs.FourierSliceExtraction()\n",
    "\n",
    "# Use this if using an atomic potential\n",
    "# potential_integrator = cxs.GaussianMixtureProjection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Tuple\n",
    "\n",
    "from jaxtyping import Array, Float\n",
    "\n",
    "from cryojax.inference import distributions as dist\n",
    "\n",
    "\n",
    "def build_distribution_from_relion_particle_parameters(\n",
    "    potential_id: Float[Array, \"\"],\n",
    "    relion_particle_parameters: RelionParticleParameters,\n",
    "    args: Tuple[\n",
    "        cxs.AbstractPotentialRepresentation,\n",
    "        cxs.AbstractPotentialIntegrator,\n",
    "        Float,\n",
    "    ],\n",
    ") -> dist.IndependentGaussianPixels:\n",
    "    potentials, potential_integrator, variance = args\n",
    "\n",
    "    structural_ensemble = cxs.DiscreteStructuralEnsemble(\n",
    "        potentials,\n",
    "        relion_particle_parameters.pose,\n",
    "        cxs.DiscreteConformationalVariable(potential_id),\n",
    "    )\n",
    "\n",
    "    scattering_theory = cxs.WeakPhaseScatteringTheory(\n",
    "        structural_ensemble,\n",
    "        potential_integrator,\n",
    "        relion_particle_parameters.transfer_theory,\n",
    "    )\n",
    "    image_model = cxs.ContrastImageModel(\n",
    "        relion_particle_parameters.instrument_config, scattering_theory\n",
    "    )\n",
    "    distribution = dist.IndependentGaussianPixels(\n",
    "        image_model,\n",
    "        variance=variance,\n",
    "    )\n",
    "    return distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figuring out the variance of the noise\n",
    "\n",
    "Before we generate images, we need to define the variance of the noise based on a given SNR. To do this you can simulate a set of noiseless images and estimate the mean of the variance inside a mask where you know you have signal. We can do this using cryoJAX's circular mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cryojax.image.operators import CircularCosineMask\n",
    "\n",
    "\n",
    "@eqx.filter_jit\n",
    "@partial(eqx.filter_vmap, in_axes=(0, eqx.if_array(0), None))\n",
    "def simulate_noiseless_images(potential_id, particle_parameters, args):\n",
    "    distribution = build_distribution_from_relion_particle_parameters(\n",
    "        potential_id, particle_parameters, args\n",
    "    )\n",
    "    return distribution.compute_signal()\n",
    "\n",
    "\n",
    "@eqx.filter_jit\n",
    "def estimate_signal_variance(\n",
    "    key, n_images_for_estimation, mask_radius, instrument_config, args, *, batch_size=None\n",
    "):\n",
    "    potentials, potential_integrator, ensemble_weights, variance = args\n",
    "\n",
    "    key, *subkeys = jax.random.split(key, n_images_for_estimation + 1)\n",
    "    subkeys = jnp.array(subkeys)\n",
    "\n",
    "    particle_parameters = make_particle_parameters(subkeys, instrument_config)\n",
    "\n",
    "    # set offset at 0 for simplicity\n",
    "    particle_parameters = eqx.tree_at(\n",
    "        lambda d: (d.pose.offset_x_in_angstroms, d.pose.offset_y_in_angstroms),\n",
    "        particle_parameters,\n",
    "        replace_fn=lambda x: 0.0 * x,\n",
    "    )\n",
    "\n",
    "    key, subkey = jax.random.split(key)\n",
    "    potential_ids = jax.random.choice(\n",
    "        subkey, ensemble_weights.shape[0], (n_images_for_estimation,), p=ensemble_weights\n",
    "    )\n",
    "    noiseless_images = simulate_noiseless_images(\n",
    "        potential_ids, particle_parameters, (potentials, potential_integrator, variance)\n",
    "    )\n",
    "\n",
    "    # define noise mask\n",
    "    mask = CircularCosineMask(\n",
    "        particle_parameters.instrument_config.coordinate_grid_in_pixels,\n",
    "        radius_in_angstroms_or_pixels=mask_radius,\n",
    "        rolloff_width_in_angstroms_or_pixels=1.0,\n",
    "    )\n",
    "\n",
    "    signal_variance = jnp.var(\n",
    "        noiseless_images, axis=(1, 2), where=jnp.where(mask.array == 1.0, True, False)\n",
    "    ).mean()\n",
    "\n",
    "    return signal_variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_est_seed = 0\n",
    "key_var_est = jax.random.key(var_est_seed)\n",
    "uniform_weights = jnp.array([0.5, 0.5])  # weights for sampling structuures\n",
    "\n",
    "signal_variance = estimate_signal_variance(\n",
    "    key_var_est,\n",
    "    n_images_for_estimation=10,\n",
    "    mask_radius=box_size // 3,\n",
    "    instrument_config=instrument_config,\n",
    "    args=(\n",
    "        potentials,\n",
    "        potential_integrator,\n",
    "        uniform_weights,\n",
    "        1.0,\n",
    "    ),  # the last argument is the variance, not needed for this\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulating the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_image_with_noise(\n",
    "    particle_parameters: RelionParticleParameters,\n",
    "    constant_args,\n",
    "    per_particle_args,\n",
    "):\n",
    "    key_noise, potential_id = per_particle_args\n",
    "    distribution = build_distribution_from_relion_particle_parameters(\n",
    "        potential_id, particle_parameters, constant_args\n",
    "    )\n",
    "    return distribution.sample(key_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snr = 0.1  # define whatever snr you want\n",
    "noise_variance = signal_variance / snr\n",
    "\n",
    "constant_args = (potentials, potential_integrator, noise_variance)\n",
    "\n",
    "# Generate RNG keys for per-image noise, and per-image conformations\n",
    "keys_noise = jax.random.split(jax.random.key(0), number_of_images)\n",
    "key_structure = jax.random.key(1)\n",
    "\n",
    "# Generate the per-image conformation assignments\n",
    "ensemble_weights = jnp.array([0.3, 0.7])  # weights for sampling structures\n",
    "potential_ids = jax.random.choice(\n",
    "    key_structure, ensemble_weights.shape[0], (number_of_images,), p=ensemble_weights\n",
    ")\n",
    "\n",
    "write_simulated_image_stack_from_starfile(\n",
    "    param_dataset=parameter_dataset,\n",
    "    compute_image_fn=compute_image_with_noise,\n",
    "    constant_args=constant_args,\n",
    "    per_particle_args=(keys_noise, potential_ids),\n",
    "    is_jittable=True,\n",
    "    batch_size_per_mrc=10,\n",
    "    overwrite=True,\n",
    "    compression=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing a likelihood Matrix\n",
    "\n",
    "Now we have a heterogeneous dataset. Let's say we have a new ensemble (I'll use the true one for simplicity), we want to generate the likelihood between each member of the ensemble and each image. This will give us a likelihood matrix, which can be used for ensemble reweighting among other things."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First load the data\n",
    "particle_reader = RelionParticleStackDataset(parameter_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cryojax.data._particle_data.ParticleStack"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(particle_reader[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up a dataloader\n",
    "\n",
    "Normally, you'll have thousands of images, so loading them all into memory at once is not a good idea. CryoJAX is very flexible, and allows us to use external dataloaders. Here I will use the dataloader implemented in: https://github.com/BirkhoffG/jax-dataloader\n",
    "\n",
    "*You will need to install the `jax_dataloader` library above to continue with the rest of the tutorial.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax_dataloader as jdl\n",
    "\n",
    "from cryojax.data import ParticleStack\n",
    "\n",
    "\n",
    "class CustomJaxDataset(jdl.Dataset):\n",
    "    def __init__(self, cryojax_dataset: RelionParticleStackDataset):\n",
    "        self.cryojax_dataset = cryojax_dataset\n",
    "\n",
    "    def __getitem__(self, index) -> ParticleStack:\n",
    "        return self.cryojax_dataset[index]\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.cryojax_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = jdl.DataLoader(\n",
    "    CustomJaxDataset(\n",
    "        particle_reader\n",
    "    ),  # Can be a jdl.Dataset or pytorch or huggingface or tensorflow dataset\n",
    "    backend=\"jax\",  # Use 'jax' backend for loading data\n",
    "    batch_size=5,  # Batch size\n",
    "    shuffle=False,  # Shuffle the dataloader every iteration or not\n",
    "    drop_last=False,  # Drop the last batch or not\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing the likelihood\n",
    "\n",
    "Here we show several ways to compute the likelihood. I will show how to compute it using vmapping, but also jax.lax.map, which is usually more memory friendly. I will also show how to compute the likelihood from a stack of atom_positions, which will be useful for computing gradients for atomic structures.\n",
    "\n",
    "In all cases we will vmap first over images and then over structures/potentials. This is because computing quantities this way is faster. Think about it this way, it is much more easier to grab one potential and compute all the images required, than to compute a potential for every image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "@eqx.filter_jit\n",
    "@partial(eqx.filter_vmap, in_axes=(None, eqx.if_array(0), None))\n",
    "def compute_likelihood(\n",
    "    potential_id,\n",
    "    particle_dataset: ParticleStack,\n",
    "    args: Any,\n",
    ") -> Float:\n",
    "    potentials, potential_integrator, variance = args\n",
    "    structural_ensemble = cxs.DiscreteStructuralEnsemble(\n",
    "        potentials,\n",
    "        particle_dataset.parameters.pose,\n",
    "        cxs.DiscreteConformationalVariable(potential_id),\n",
    "    )\n",
    "\n",
    "    scattering_theory = cxs.WeakPhaseScatteringTheory(\n",
    "        structural_ensemble,\n",
    "        potential_integrator,\n",
    "        particle_dataset.parameters.transfer_theory,\n",
    "    )\n",
    "    imaging_pipeline = cxs.ContrastImageModel(\n",
    "        particle_dataset.parameters.instrument_config, scattering_theory\n",
    "    )\n",
    "    distribution = dist.IndependentGaussianPixels(\n",
    "        imaging_pipeline,\n",
    "        variance=variance,\n",
    "    )\n",
    "    return distribution.log_likelihood(particle_dataset.images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing with equinox.filter_vmap\n",
    "\n",
    "This is the simplest way to compute the likelihood matrix. Simply set a batch_size in the dataloader such that you don't get memory errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "@eqx.filter_jit\n",
    "@partial(eqx.filter_vmap, in_axes=(0, None, None))\n",
    "def compute_likelihood_batch(potential_id, relion_particle_stack, args):\n",
    "    return compute_likelihood(potential_id, relion_particle_stack, args)\n",
    "\n",
    "\n",
    "def compute_likelihood_matrix(dataloader, args):\n",
    "    n_potentials = len(args[0])\n",
    "    likelihood_matrix = []\n",
    "    for batch in dataloader:\n",
    "        batch_likelihood = compute_likelihood_batch(\n",
    "            jnp.arange(n_potentials), batch, args\n",
    "        ).T\n",
    "        likelihood_matrix.append(batch_likelihood)\n",
    "    likelihood_matrix = jnp.concatenate(likelihood_matrix, axis=0)\n",
    "    return likelihood_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood_matrix = compute_likelihood_matrix(\n",
    "    dataloader, args=(potentials, potential_integrator, noise_variance)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Array(65, dtype=int32), Array(35, dtype=int32))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's compute the populations\n",
    "# They should be around 0.7 and 0.3 (might not be true at low snr)\n",
    "\n",
    "(\n",
    "    jnp.sum(jnp.argmin(likelihood_matrix, axis=1) == 0),\n",
    "    jnp.sum(jnp.argmin(likelihood_matrix, axis=1) == 1),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing with jax.lax.map\n",
    "\n",
    "Here we need to use equinox partition, as jax.lax.map does not have utilities such as eqx.if_array (see how we vmapped in the previous example). The filtering is very simple, we just need to get rid of all leaves that are not arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "@eqx.filter_jit\n",
    "def compute_single_likelihood(\n",
    "    potential_id,\n",
    "    particle_stack_map: ParticleStack,\n",
    "    particle_stack_nomap: ParticleStack,\n",
    "    args: Any,\n",
    ") -> Float:\n",
    "    particle_stack = eqx.combine(particle_stack_map, particle_stack_nomap)\n",
    "    potentials, potential_integrator, variance = args\n",
    "    structural_ensemble = cxs.DiscreteStructuralEnsemble(\n",
    "        potentials,\n",
    "        particle_stack.parameters.pose,\n",
    "        cxs.DiscreteConformationalVariable(potential_id),\n",
    "    )\n",
    "\n",
    "    scattering_theory = cxs.WeakPhaseScatteringTheory(\n",
    "        structural_ensemble,\n",
    "        potential_integrator,\n",
    "        particle_stack.parameters.transfer_theory,\n",
    "    )\n",
    "    imaging_pipeline = cxs.ContrastImageModel(\n",
    "        particle_stack.parameters.instrument_config, scattering_theory\n",
    "    )\n",
    "    distribution = dist.IndependentGaussianPixels(\n",
    "        imaging_pipeline,\n",
    "        variance=variance,\n",
    "    )\n",
    "    return distribution.log_likelihood(particle_stack.images)\n",
    "\n",
    "\n",
    "@eqx.filter_jit\n",
    "def compute_likelihood_with_map(potential_id, particle_stack, args, *, batch_size_images):\n",
    "    \"\"\"\n",
    "    Computes one row of the likelihood matrix (all structures, one image)\n",
    "    \"\"\"\n",
    "\n",
    "    stack_map, stack_nomap = eqx.partition(particle_stack, eqx.is_array)\n",
    "\n",
    "    likelihood_batch = jax.lax.map(\n",
    "        lambda x: compute_single_likelihood(potential_id, x, stack_nomap, args),\n",
    "        xs=stack_map,\n",
    "        batch_size=batch_size_images,  # compute for this many images in parallel\n",
    "    )\n",
    "    return likelihood_batch\n",
    "\n",
    "\n",
    "def compute_likelihood_matrix_with_lax_map(\n",
    "    dataloader, args, *, batch_size_potentials=None, batch_size_images=None\n",
    "):\n",
    "    n_potentials = len(args[0])\n",
    "    likelihood_matrix = []\n",
    "    for batch in dataloader:\n",
    "        batch_likelihood = jax.lax.map(\n",
    "            lambda x: compute_likelihood_with_map(\n",
    "                x, batch, args, batch_size_images=batch_size_images\n",
    "            ),\n",
    "            xs=jnp.arange(n_potentials),\n",
    "            batch_size=batch_size_potentials,  # potentials to compute in parallel\n",
    "        ).T\n",
    "        likelihood_matrix.append(batch_likelihood)\n",
    "    likelihood_matrix = jnp.concatenate(likelihood_matrix, axis=0)\n",
    "    return likelihood_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will take longer, but uses less memory. Play around with the batch sizes. Batch size potentials controls how many potentials are used in a single vmap operation. Batch size images controls how many images are used in a single vmap operation. Atomic potentials are cheap when it comes to memory, but they are slower when comparing against many images. Voxel potentials are more memory expensive, but it's vary fast to compare them against many images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood_matrix_lax_map = compute_likelihood_matrix_with_lax_map(\n",
    "    dataloader,\n",
    "    args=(potentials, potential_integrator, noise_variance),\n",
    "    batch_size_potentials=2,\n",
    "    batch_size_images=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(True, dtype=bool)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnp.allclose(likelihood_matrix_lax_map, likelihood_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing likelihood matrix from multiple atomic positions\n",
    "\n",
    "For this approach we need a little trick to be able to jit the generation of the peng atomic potential. Here we will not convert the atomic potential to a voxel potential, as the objective of this tutorial is to be able to create a loss function that allows for the computation of gradients for the atomic positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@eqx.filter_jit\n",
    "@partial(eqx.filter_vmap, in_axes=(None, eqx.if_array(0), None))\n",
    "def compute_likelihood_atomic(\n",
    "    potential, particle_stack: ParticleStack, variance\n",
    ") -> Float:\n",
    "    structural_ensemble = cxs.SingleStructureEnsemble(\n",
    "        potential,\n",
    "        particle_stack.parameters.pose,\n",
    "    )\n",
    "\n",
    "    scattering_theory = cxs.WeakPhaseScatteringTheory(\n",
    "        structural_ensemble,\n",
    "        cxs.GaussianMixtureProjection(use_error_functions=True),\n",
    "        particle_stack.parameters.transfer_theory,\n",
    "    )\n",
    "    imaging_pipeline = cxs.ContrastImageModel(\n",
    "        particle_stack.parameters.instrument_config, scattering_theory\n",
    "    )\n",
    "    distribution = dist.IndependentGaussianPixels(\n",
    "        imaging_pipeline,\n",
    "        variance=variance,\n",
    "    )\n",
    "    return distribution.log_likelihood(particle_stack.images)\n",
    "\n",
    "\n",
    "@eqx.filter_jit\n",
    "@partial(eqx.filter_vmap, in_axes=(0, None, None))\n",
    "def compute_likelihood_build_potential(atom_positions, particle_stack, args):\n",
    "    b_factors, parameter_table, variance = args\n",
    "    atom_potential = cxs.PengAtomicPotential(\n",
    "        atom_positions,\n",
    "        scattering_factor_a=parameter_table[\"a\"],\n",
    "        scattering_factor_b=parameter_table[\"b\"],\n",
    "        b_factors=b_factors,\n",
    "    )\n",
    "    return compute_likelihood_atomic(atom_potential, particle_stack, variance)\n",
    "\n",
    "\n",
    "def compute_likelihood_matrix_from_atoms(atom_positions, dataloader, args):\n",
    "    likelihood_matrix = []\n",
    "    for batch in dataloader:\n",
    "        batch_likelihood = compute_likelihood_build_potential(\n",
    "            atom_positions, batch, args\n",
    "        ).T  # we want something with shape (n_images, n_atom_positions)\n",
    "\n",
    "        likelihood_matrix.append(batch_likelihood)\n",
    "    likelihood_matrix = jnp.concatenate(likelihood_matrix, axis=0)\n",
    "    return likelihood_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WARNING\n",
    "Here I am assuming that all atomic structures have the same set of atoms. Generalizing is not difficult, you just need to be careful about how you handle the atom_identities and the b_factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "filenames = [\"./data/groel_chainA.pdb\", \"./data/groel_chainA_holo.pdb\"]\n",
    "\n",
    "box_size = parameter_dataset[0].instrument_config.shape[0]\n",
    "voxel_size = parameter_dataset[0].instrument_config.pixel_size\n",
    "\n",
    "single_atom_positions, atom_identities, b_factors = read_atoms_from_pdb(\n",
    "    filenames[0], center=True, select=\"not element H\", loads_b_factors=True\n",
    ")\n",
    "\n",
    "atom_positions = np.zeros((len(filenames), *single_atom_positions.shape))\n",
    "atom_positions[0] = single_atom_positions\n",
    "\n",
    "for i, filename in enumerate(filenames[1:]):\n",
    "    # Load the atomic structure and transform into a potential\n",
    "    atom_positions[i + 1] = read_atoms_from_pdb(\n",
    "        filename, center=True, select=\"not element H\", loads_b_factors=False\n",
    "    )[0]  # we are only interested in the positions, the resto does not change\n",
    "\n",
    "atom_positions = jnp.array(atom_positions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with earlier, we need to load the parameter table for the Peng Atomic Potential, otherwise generating it is not jittable (this pre-loads the atomic scattering factors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_table = get_tabulated_scattering_factor_parameters(atom_identities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = (b_factors, parameter_table, noise_variance)\n",
    "\n",
    "likelihood_matrix_atoms = compute_likelihood_matrix_from_atoms(\n",
    "    atom_positions, dataloader, args\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Array(65, dtype=int32), Array(35, dtype=int32))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    jnp.sum(jnp.argmin(likelihood_matrix_atoms, axis=1) == 0),\n",
    "    jnp.sum(jnp.argmin(likelihood_matrix_atoms, axis=1) == 1),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cryojax",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
